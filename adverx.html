<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="AdverX-Ray: Ensuring X-Ray Integrity Through Frequency-Sensitive Adversarial VAEs">  <!-- TODO: fill this field -->
  <meta name="keywords" content="Keywords">  <!-- TODO: fill this field -->
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>AdverX-Ray</title>  <!-- TODO: fill this field -->
  <link rel="icon" href="logos/xray.png">

  <!-- Global site tag (gtag.js) - Google Analytics -->
<!--  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>-->
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./css/bulma.min.css">
  <link rel="stylesheet" href="./css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./css/bulma-slider.min.css">
  <link rel="stylesheet" href="./css/fontawesome.all.min.css">
<!--  <link rel="stylesheet"-->
<!--        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">-->
  <link rel="stylesheet" href="academicons-1.9.4/css/academicons.css">
  <link rel="stylesheet" href="./css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./js/fontawesome.all.min.js"></script>
  <script src="./js/bulma-carousel.min.js"></script>
  <script src="./js/bulma-slider.min.js"></script>
  <script src="./js/index.js"></script>
  <script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=default'></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="index.html">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <a class="navbar-item" href="index.html#Pubs">
        More research
      </a>
    </div>

  </div>
</nav>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">AdverX-Ray: Ensuring X-Ray Integrity Through Frequency-Sensitive Adversarial VAEs</h1>  <!-- TODO: fill this field -->
          <div class="is-size-5 publication-authors">    <!-- TODO: complete this field -->
            <span class="author-block">
              <a href="index.html">Francisco Caetano</a><sup>1*</sup>,</span>
            <span class="author-block">
              <a href="https://research.tue.nl/en/persons/christiaan-ga-viviers">Christiaan Viviers</a><sup>1*</sup>,</span>
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=7277F1MAAAAJ&hl=en">Lena Filatova</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://www.tue.nl/en/research/researchers/peter-de-with">Peter H.N. de With</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://www.tue.nl/en/research/researchers/fons-van-der-sommen">Fons van der Sommen</a><sup>1</sup></span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Eindhoven University of Technology <sup>2</sup>Philips IGT</span>
            <p><sup>*</sup>Equal Contribution</p>
            <p>Runner-Up Robert F. Wagner Award at SPIE Medical Imaging 2025</p>  <!-- TODO: complete this field -->
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">  <!-- TODO: fill this field -->
                <a href="https://arxiv.org/abs/2502.16610" target="_blank"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">  <!-- TODO: fill this field -->
                <a href="https://zenodo.org/records/13924900" target="_blank"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Dataset</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">  <!-- TODO: fill this field -->
                <a href="https://github.com/caetas/AdverX" target="_blank"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="images/AdverXRay.png"
                 class="interpolation-image"
                 alt="description of what image is showing."/>
          </div>
      <h2 class="subtitle has-text-centered">  <!-- TODO: fill this field -->
        AdverX-Ray is an X-ray tailored Adversarial VAE framework that, when fed a batch of patches from an X-ray scan,
        can detect covariate shifts effectively.
      </h2>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">  <!-- TODO: fill this field -->
          <!-- Reminders:
              - you can use paragraph sections to make the abstract much more reader friendly.
              - use <i></i> to highlight parts of text -->
          <p>
            Ensuring the quality and integrity of medical images is crucial for maintaining diagnostic accuracy in deep
            learning-based Computer-Aided Diagnosis and Computer-Aided Detection (CAD) systems. Covariate shifts —
            subtle variations in data distribution caused by different imaging devices or settings — can severely degrade
            model performance, similar to the effects of adversarial attacks. Therefore, it is vital to have a lightweight, fast
            method to assess the quality of these images before feeding them into CAD models. AdverX-Ray addresses this
            need by serving as an image quality assessment layer, designed to detect covariate shifts effectively.
          </p>
          <p>
            This Adversarial Variational Autoencoder prioritizes the discriminator's role, using the generator's suboptimal outputs as
            negative samples to fine-tune the discriminator's ability to identify high-frequency artifacts. Images generated by
            adversarial networks often exhibit severe high-frequency artifacts, leading the discriminator to focus excessively
            on these components. This makes the discriminator ideal for this task. Trained on patches from X-ray images of
            specific machine models, AdverX-Ray can evaluate whether a scan matches the training distribution or if a scan
            from the same machine was captured under different settings. Extensive comparisons with various OOD detection methods show that AdverX-Ray significantly outperforms existing techniques, achieving a 96.2% average
            AUROC using only 64 random patches from an X-ray. Its lightweight and fast architecture makes it suitable for
            real-time applications, enhancing the reliability of medical imaging systems.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <section class="section">  <!-- TODO: fill this entire section with content -->
      <div class="container is-max-desktop">
    
        <!-- Content section 1. -->
        <div class="columns is-centered">
          <div class="column is-full-width">
            <h2 class="title is-3">X-Ray Datasets</h2>
            <div class="content has-text-justified">
            <p>
              Medical X-ray images contain covariate factors that can compromise image
              quality and diagnostic accuracy. It is crucial to be able to detect changes in the imaging system (or
              faulty behavior) that present themselves as OOD covariate shifts in the images.
            </p>
            <div class="content has-text-centered">
              <img src="images/datasets.png"
                   width="100%"
                   class="interpolation-image"
                   alt="description of what image is showing."/>
              <p> On the left, patches from the Philips X-ray dataset, showcasing different fluoroscopy and exposure doses. On
                the right, example chest X-ray images and patches from the BIMCV-COVID19+, each from a different machine.</p>
            </div>
            </div>
            <br/>
    
            <!-- Paragraph 1. -->
            <h3 class="title is-4">Philips X-Ray Dataset</h3>
            <div class="content has-text-justified">
              <p>
                To simulate real covariate shifts in X-ray imaging without access to OOD artifacts or faulty images, capture settings were altered in an X-Ray scanner to capture subtle variations in the images. 
                A new dataset was created using an Azurion Image-Guided Therapy (IGT) system, capturing 12-bit DICOM X-ray images of a standard test object (a clock) across different 
                dose levels and source-image distances (SID) in pulsed fluoroscopy and full radiation modes. Six primary imaging modes were defined, ranging from normal-dose exposures 
                at 110 cm SID (Mode 0, considered ID) to low-dose fluoroscopy at 90 cm SID (Mode 5, the most OOD). The dataset, comprising 18 modes across two environments, 
                is publicly available with the paper.
              </p>
            </div>
            <br/>
            <!--/ Paragraph 2. -->
    
            <!-- Paragraph 3. -->
            <h3 class="title is-4">BIMCV-COVID19+</h3>
            <div class="content has-text-justified">
              <p>The dataset, sourced from the Medical Image Data Bank of the Valencian Community (BIMCV), includes CR, DX, and CT images of COVID-19 patients alongside their clinical findings and reports. It 
                comprises 1,380 CX, 885 DX, and 163 CT studies from 1,311 COVID-19+ patients, totaling 3,141 X-ray and 2,239 CT images. This study focuses exclusively on the X-ray scans, grouped by 29 machine 
                models to simulate real-world scenarios where models trained on one machine's data must process images from others, risking performance degradation. For experiments, five distinct ID sets were 
                defined, each based on images from the five machines with the highest scan counts.</p>
                </div>
            </div>
          </section>

            <!--/ Paragraph 3. -->

<section class="section">  <!-- TODO: fill this entire section with content -->
  <div class="container is-max-desktop">

    <!-- Content section 1. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">AdverX-Ray</h2>
        <div class="content has-text-justified">
        <p>
        A common generative-based OOD detection approach uses trained models to identify unseen samples, while adversarially trained discriminators define boundaries for ID sets by estimating the probability of a sample 
        being real (ID) or synthetic (OOD). Building on this, AdverX-Ray is introduced as an X-ray-specific Adversarial VAE framework that detects covariate shifts by processing batches of patches from X-ray scans. 
        AdverX-Ray is a modified version of the Discriminative Covariate Shift Patch-based Network (DisCoPatch).
        </p>
        </div>
        <br/>

        <!-- Paragraph 1. -->
        <h3 class="title is-4">Overview</h3>
        <div class="content has-text-justified">
          <p>
            AdverX-Ray combines generative and reconstruction-based methods to train a discriminator for unsupervised OOD detection. The VAE minimizes the Evidence Lower Bound (ELBO) loss while generating samples and 
            reconstructions designed to challenge the discriminator. Unlike standard GANs, AdverX-Ray's discriminator is trained to distinguish not only real versus generated images but also reconstructed images. 
            This dual training addresses key weaknesses: VAEs often produce reconstructions lacking high-frequency details crucial for detecting shifts like blurriness, while GANs overly emphasize high-frequency differences, 
            risking neglect of low-frequency content.</p>
            <p>AdverX-Ray aligns the discriminator's understanding with the ID frequency spectrum by balancing training on both types of images and refining their realism. Batch normalization further enhances the discriminator 
              by leveraging batch statistics to differentiate distributions, modeling correlations across patches within scans and capturing global X-ray structures. Although this method processes scans individually, it remains 
              efficient due to the discriminator's lightweight design, offering a robust mechanism for OOD detection.
          </p>
        </div>
        <br/>
        <!--/ Paragraph 2. -->

        <!-- Paragraph 4. -->
        <h3 class="title is-4">Model Performance</h3>
        <div class="content has-text-justified">
          <p>
            The results highlight the performance of OOD detection methods in the X-ray setting, where varying acquisition parameters can introduce heteroscedastic noise into the signal. Covariate shifts in this context are 
            often intractable and generally not perceptible to non-specialists. However, with the exception of the GLOW model trained on typicality, all other methods effectively detect shifts in high-level image statistics.
          </p>
          
          <table style="width: 100%; text-align: center;">
            <caption style="font-weight: bold; margin-bottom: 10px;">Table 1 - AUROC Scores of Various Methods on Detecting OOD Covariate Shift on the Philips X-Ray Dataset.</caption>
            <thead>
              <tr>
                  <th>Methods</th>
                  <th>Mode 1</th>
                  <th>Mode 2</th>
                  <th>Mode 3</th>
                  <th>Mode 4</th>
                  <th>Mode 5</th>
                  <th>Average AUROC↑/FPR95↓</th>
              </tr>
          </thead>
          <tbody>
              <tr>
                  <td>DDPM (T250: LPIPS)</td>
                  <td>86.4</td>
                  <td>88.5</td>
                  <td>84.2</td>
                  <td>89.3</td>
                  <td>96.5</td>
                  <td>89.0 / 69.4</td>
              </tr>
              <tr>
                  <td>DDPM (T250: LPIPS + MSE)</td>
                  <td>79.9</td>
                  <td>83.0</td>
                  <td>81.1</td>
                  <td>89.0</td>
                  <td>95.8</td>
                  <td>85.8 / 67.3</td>
              </tr>
              <tr>
                  <td>VAE (ELBO)</td>
                  <td>69.7</td>
                  <td>96.1</td>
                  <td>88.9</td>
                  <td>91.3</td>
                  <td>98.1</td>
                  <td>88.8 / 25.0</td>
              </tr>
              <tr>
                  <td>AVAE (ELBO + Adv Loss)</td>
                  <td>65.5</td>
                  <td>94.8</td>
                  <td>86.5</td>
                  <td>89.5</td>
                  <td>97.2</td>
                  <td>86.7 / 28.9</td>
              </tr>
              <tr>
                  <td>GLOW (LL)</td>
                  <td>89.3</td>
                  <td>98.8</td>
                  <td>99.8</td>
                  <td>99.9</td>
                  <td><strong>100.0</strong></td>
                  <td>97.6 / 8.7</td>
              </tr>
              <tr>
                  <td>GLOW (Typicality)</td>
                  <td>30.4</td>
                  <td>16.5</td>
                  <td>15.1</td>
                  <td>10.4</td>
                  <td>11.1</td>
                  <td>16.7 / 99.8</td>
              </tr>
              <tr>
                  <td><strong>AdverX-Ray (Proposed)</strong></td>
                  <td><strong>99.5</strong></td>
                  <td><strong>99.9</strong></td>
                  <td><strong>99.9</strong></td>
                  <td><strong>100.0</strong></td>
                  <td><strong>100.0</strong></td>
                  <td><strong>100.0 / 0.0</strong></td>
              </tr>
          </tbody>
          </table>

          <p>
            The results demonstrate that AdverX-Ray performs effectively across all ID sets, in contrast to both the VAE and GLOW models. GLOW exhibits poor performance due to a known issue where it assigns higher likelihoods to OOD images. Interestingly, this limitation is not consistent, as it only occurs with certain OOD machine models. AdverX-Ray consistently outperforms both VAE and GLOW across all test sets, except for the GE machine, where VAE achieves slightly better results.
          </p>

          <table style="width: 100%; text-align: center;">
            <caption style="font-weight: bold; margin-bottom: 10px;">Table 2 - AUROC Scores of Various Methods on Detecting OOD Covariate Shift on the BIMCV-COVID19+ Dataset.</caption>
            <thead>
              <tr>
                  <th>Methods</th>
                  <th>Siemens</th>
                  <th>Konica</th>
                  <th>Philips</th>
                  <th>GE</th>
                  <th>GMM</th>
                  <th>Average AUROC↑/FPR95↓</th>
              </tr>
          </thead>
          <tbody>
            <tr>
                <td>VAE (ELBO)</td>
                <td>49.7</td>
                <td>30.6</td>
                <td>38.8</td>
                <td><strong>98.6</strong></td>
                <td>62.3</td>
                <td>56.0 / 81.5</td>
            </tr>
            <tr>
                <td>GLOW (LL)</td>
                <td>31.4</td>
                <td>34.2</td>
                <td>18.9</td>
                <td>88.1</td>
                <td>90.6</td>
                <td>52.7 / 95.2</td>
            </tr>
            <tr>
                <td><strong>AdverX-Ray (Proposed)</strong></td>
                <td><strong>96.3</strong></td>
                <td><strong>96.3</strong></td>
                <td><strong>96.1</strong></td>
                <td>92.4</td>
                <td><strong>99.7</strong></td>
                <td><strong>96.2 / 19.7</strong></td>
            </tr>
        </tbody>
          </table>
          
          <p>Additionally, while Table 1 shows that the VAE and GLOW models effectively detect high-frequency covariate shifts within the Philips X-ray dataset, 
            their narrow focus on these components proves insufficient for distinguishing scans from different manufacturers. In contrast, the AdverX-Ray model, 
            with its broader frequency coverage, successfully addresses this limitation. It is worth noting that AdverX-Ray achieves these results with a model size of just 15MB, 
            significantly smaller than the VAE (126MB) and GLOW (120MB). The results are based on the average of five runs, using 64 random patches per image.</p>
        </div>
            <div class="content has-text-centered">
            <img src="images/scores_machine.png"
                 width="100%"
                 class="interpolation-image"
                 alt="description of what image is showing."/>
            <p>Examples of OOD scores generated by the AdverX-Ray model trained on the Philips machine scans.</p>
          </div>
          </div>
        </div>
      </div>
    </div>
    <!--/ Content section 1. -->
  </div>
  <!-- Repeat content sections if required -->
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{x,
  author    = {x},
  title     = {x},
  journal   = {x},
  year      = {x},
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This page is adapted from <a
              href="https://github.com/nerfies/nerfies.github.io">Nerfies</a> under the <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>